{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d66ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.utils import dropout_adj\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch_geometric.datasets import Planetoid, CitationFull\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from torch_geometric.nn import SAGEConv, GCNConv\n",
    "\n",
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "\n",
    "from GCL.eval import get_split, LREvaluator\n",
    "\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bd4ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_feature(x, drop_prob):\n",
    "    drop_mask = torch.empty(\n",
    "        (x.size(1), ),\n",
    "        dtype=torch.float32,\n",
    "        device=x.device).uniform_(0, 1) < drop_prob\n",
    "    x = x.clone()\n",
    "    x[:, drop_mask] = 0\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e77f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, edge_index, topo_embedding, lam, batch_size,\n",
    "          model, optimizer, drop_edge_rate_1, drop_edge_rate_2,\n",
    "          drop_feature_rate_1, drop_feature_rate_2, data):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    edge_index_1 = dropout_adj(edge_index, p=drop_edge_rate_1)[0]\n",
    "    edge_index_2 = dropout_adj(edge_index, p=drop_edge_rate_2)[0]\n",
    "    x_1 = drop_feature(x, drop_feature_rate_1)\n",
    "    x_2 = drop_feature(x, drop_feature_rate_2)\n",
    "    z1, z2 = model(x_1, edge_index_1, x_2, edge_index_2)\n",
    "    if batch_size == 0:\n",
    "        feat_cor = data.x @ data.x.t()\n",
    "        topo_cor = topo_embedding @ topo_embedding.t()\n",
    "        loss = model.loss(z1, z2, feat_cor, topo_cor, lam)\n",
    "    else:\n",
    "        loss = model.batch_loss(z1, z2, data.x, topo_embedding, lam, batch_size)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, x, edge_index, y, final=False):\n",
    "    model.eval()\n",
    "    z = model.get_embedding(x, edge_index)\n",
    "    result = label_classification(z, y, ratio=0.1)\n",
    "    #print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e7cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyg_test(encoder_model, x, edge_index, y, test_times = 10):\n",
    "    encoder_model.eval()\n",
    "    z = encoder_model.get_embedding(x, edge_index) #, data.edge_attr\n",
    "    mi = []\n",
    "    ma = []\n",
    "    for i in range(test_times):\n",
    "        split = get_split(num_samples=z.size()[0], train_ratio=0.1, test_ratio=0.8)\n",
    "        result = LREvaluator()(z, y, split)\n",
    "        mi.append(result['micro_f1'])\n",
    "        ma.append(result['macro_f1'])\n",
    "    print(\n",
    "        'Mi_mean: ',str( torch.tensor(mi).mean().item() ),\n",
    "        ' Mi_std: ',str( torch.tensor(mi).std().item() ),\n",
    "        ' Ma_mean: ',str( torch.tensor(ma).mean().item() ),\n",
    "        ' Ma_std: ',str( torch.tensor(ma).std().item() ),\n",
    "    )\n",
    "    \n",
    "    return torch.tensor(mi).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b2307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(action='ignore', category=DeprecationWarning, message='`np.bool` is a deprecated alias')\n",
    "\n",
    "from Dataset_Load import load_dataset\n",
    "from Model import DC\n",
    "\n",
    "from Test import label_classification\n",
    "\n",
    "from Topo_embedding import get_GraRep_topo_embedding, get_PPR_topo_embedding\n",
    "\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import random\n",
    "\n",
    "#env_load\n",
    "def parameters_test(config):\n",
    "    \n",
    "    torch.manual_seed(config['seed'])\n",
    "    random.seed(12345)\n",
    "    \n",
    "    learning_rate = config['learning_rate']\n",
    "    num_hidden = config['num_hidden']\n",
    "    num_proj_hidden = config['num_proj_hidden']\n",
    "    activation = ({'relu': F.relu, 'prelu': nn.PReLU()})[config['activation']]\n",
    "    base_model = ({'GCNConv': GCNConv})[config['base_model']]\n",
    "    num_layers = config['num_layers']\n",
    "    batch_size = config['batch_size']\n",
    "\n",
    "    drop_edge_rate_1 = config['drop_edge_rate_1']\n",
    "    drop_edge_rate_2 = config['drop_edge_rate_2']\n",
    "    drop_feature_rate_1 = config['drop_feature_rate_1']\n",
    "    drop_feature_rate_2 = config['drop_feature_rate_2']\n",
    "    num_epochs = config['num_epochs']\n",
    "    weight_decay = config['weight_decay']\n",
    "\n",
    "    topo_demension = config['topo_demension']\n",
    "    topo_order = config['topo_order']\n",
    "    topo_iter = config['topo_iter']\n",
    "    topo_seed = config['topo_seed']\n",
    "    topo_lam = config['topo_lam']\n",
    "    topo_self_loop = config['topo_self_loop']\n",
    "    topo_alpha = config['topo_alpha']   \n",
    "\n",
    "    dataset_name = config['dataset_name']\n",
    "    dataset_path = config['dataset_dir']\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "    #begin\n",
    "    dataset = load_dataset(dataset_name, dataset_path)\n",
    "    data = dataset[0]\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data = data.to(device)\n",
    "\n",
    "    model = DC(dataset.num_features, num_hidden, num_layers).to(device)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    \n",
    "    if Path(config['topo_dir']+config['dataset_name']+config['topo_method']+'.pt').is_file():\n",
    "        topo_embedding = torch.load(config['topo_dir']+config['dataset_name']+config['topo_method']+'.pt')\n",
    "    else:\n",
    "        print('Culculate Topo_Embedding')\n",
    "\n",
    "        if config['topo_method'] == 'GraRep':\n",
    "            topo_embedding = get_GraRep_topo_embedding(data.clone().to(torch.device('cpu')),\n",
    "                                                       dimensions = topo_demension, \n",
    "                                                       iterations = topo_iter, \n",
    "                                                       order = topo_order, \n",
    "                                                       seed = topo_seed).to(device)\n",
    "        elif config['topo_method'] == 'PPR':\n",
    "            topo_embedding = get_PPR_topo_embedding(data.clone().to(torch.device('cpu')),\n",
    "                                                       demensions = topo_demension,\n",
    "                                                       self_loop = topo_self_loop,\n",
    "                                                       iterations = topo_iter,\n",
    "                                                       alpha = topo_alpha).to(device)\n",
    "        topo_embedding = F.normalize(topo_embedding)\n",
    "        torch.save(topo_embedding,\n",
    "                  config['topo_dir']+config['dataset_name']+config['topo_method']+'.pt'\n",
    "                  )\n",
    "        \n",
    "\n",
    "    for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "        loss = train(data.x, data.edge_index, topo_embedding, topo_lam, batch_size,\n",
    "                     model, optimizer, drop_edge_rate_1, drop_edge_rate_2, \n",
    "                     drop_feature_rate_1, drop_feature_rate_2, data)\n",
    "\n",
    "        # print(f'(T) | Epoch={epoch:03d}, loss={loss:.4f} ')\n",
    "\n",
    "    print(\"=== Final ===\")\n",
    "    if config['test'] == 'GRACE_TEST':\n",
    "        return test(model, data.x, data.edge_index, data.y, final=True)\n",
    "    elif config['test'] == 'PYG_TEST':\n",
    "        return pyg_test(model, data.x, data.edge_index, data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f793587",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'dataset_name': 'Photo',\n",
    "    'dataset_dir': './datasets',\n",
    "    'batch_size': 0,\n",
    "    \n",
    "    'learning_rate': 5e-5,\n",
    "    'num_hidden': 1024,\n",
    "    'num_proj_hidden': 1024,\n",
    "    'activation': 'relu',\n",
    "    'base_model': 'GCNConv',\n",
    "    'num_layers': 2,\n",
    "    'drop_edge_rate_1': 0.2,\n",
    "    'drop_edge_rate_2': 0.0,\n",
    "    'drop_feature_rate_1': 0.3,\n",
    "    'drop_feature_rate_2': 0.2,\n",
    "    'num_epochs': 1500,\n",
    "    'weight_decay': 5e-5,\n",
    "    \n",
    "    'topo_method':'GraRep',\n",
    "    'topo_dir':'./topo_embedding/',\n",
    "    #PPR\n",
    "    #'topo_demension': 50, #shared\n",
    "    'topo_self_loop': True,\n",
    "    'topo_alpha':0.2, \n",
    "    #'topo_iter':20, #shared\n",
    "    \n",
    "    #GraRep\n",
    "    'topo_demension': 8,#shared\n",
    "    'topo_order': 3,\n",
    "    'topo_iter': 20,#shared\n",
    "    'topo_seed': 42,\n",
    "    \n",
    "    \n",
    "    'topo_lam': 0.0005,\n",
    "    \n",
    "    'log_root': './log/',\n",
    "    \n",
    "    'test': 'GRACE_TEST',\n",
    "    \n",
    "    'seed': 23344\n",
    "}\n",
    "result = parameters_test(config)\n",
    "with open(config['log_root']+config['dataset_name']+'.txt', 'a') as f:\n",
    "    f.write('\\n')\n",
    "    f.write(str(config.items()) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HYQ",
   "language": "python",
   "name": "hyq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
